{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d857d622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T08:53:24.627746Z",
     "iopub.status.busy": "2025-11-23T08:53:24.627475Z",
     "iopub.status.idle": "2025-11-23T09:33:17.461692Z",
     "shell.execute_reply": "2025-11-23T09:33:17.460794Z"
    },
    "papermill": {
     "duration": 2392.838939,
     "end_time": "2025-11-23T09:33:17.463175",
     "exception": false,
     "start_time": "2025-11-23T08:53:24.624236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 08:53:26.108019: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763888006.308713      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763888006.370605      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split done.\n",
      "Found 8323 images belonging to 10 classes.\n",
      "Found 2084 images belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763888093.807383      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1763888093.808139      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763888118.973333      76 service.cc:148] XLA service 0x7fe7c4003ce0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1763888118.974144      76 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1763888118.974164      76 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1763888121.801160      76 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1763888133.201875      76 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 - 212s - 812ms/step - accuracy: 0.3511 - loss: 1.9764 - val_accuracy: 0.4765 - val_loss: 1.5834\n",
      "Epoch 2/15\n",
      "261/261 - 150s - 576ms/step - accuracy: 0.5363 - loss: 1.4165 - val_accuracy: 0.5787 - val_loss: 1.2915\n",
      "Epoch 3/15\n",
      "261/261 - 148s - 569ms/step - accuracy: 0.6028 - loss: 1.2151 - val_accuracy: 0.6392 - val_loss: 1.1218\n",
      "Epoch 4/15\n",
      "261/261 - 154s - 592ms/step - accuracy: 0.6392 - loss: 1.1070 - val_accuracy: 0.6751 - val_loss: 1.0091\n",
      "Epoch 5/15\n",
      "261/261 - 147s - 562ms/step - accuracy: 0.6752 - loss: 1.0117 - val_accuracy: 0.7025 - val_loss: 0.9293\n",
      "Epoch 6/15\n",
      "261/261 - 150s - 576ms/step - accuracy: 0.6957 - loss: 0.9496 - val_accuracy: 0.7212 - val_loss: 0.8898\n",
      "Epoch 7/15\n",
      "261/261 - 149s - 569ms/step - accuracy: 0.7065 - loss: 0.9012 - val_accuracy: 0.7260 - val_loss: 0.8500\n",
      "Epoch 8/15\n",
      "261/261 - 149s - 571ms/step - accuracy: 0.7214 - loss: 0.8371 - val_accuracy: 0.7361 - val_loss: 0.8248\n",
      "Epoch 9/15\n",
      "261/261 - 147s - 564ms/step - accuracy: 0.7449 - loss: 0.7962 - val_accuracy: 0.7514 - val_loss: 0.7862\n",
      "Epoch 10/15\n",
      "261/261 - 149s - 569ms/step - accuracy: 0.7518 - loss: 0.7783 - val_accuracy: 0.7596 - val_loss: 0.7639\n",
      "Epoch 11/15\n",
      "261/261 - 148s - 566ms/step - accuracy: 0.7578 - loss: 0.7366 - val_accuracy: 0.7615 - val_loss: 0.7562\n",
      "Epoch 12/15\n",
      "261/261 - 148s - 566ms/step - accuracy: 0.7723 - loss: 0.7107 - val_accuracy: 0.7783 - val_loss: 0.7106\n",
      "Epoch 13/15\n",
      "261/261 - 148s - 568ms/step - accuracy: 0.7873 - loss: 0.6793 - val_accuracy: 0.7817 - val_loss: 0.6870\n",
      "Epoch 14/15\n",
      "261/261 - 148s - 567ms/step - accuracy: 0.7931 - loss: 0.6533 - val_accuracy: 0.7913 - val_loss: 0.6764\n",
      "Epoch 15/15\n",
      "261/261 - 150s - 576ms/step - accuracy: 0.7956 - loss: 0.6392 - val_accuracy: 0.8004 - val_loss: 0.6327\n",
      "DenseNet model saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "SEED = 42\n",
    "IMG_SIZE = (256, 256)\n",
    "BATCH = 32\n",
    "\n",
    "SOURCE = \"/kaggle/input/paddy-disease-classification/train_images\"\n",
    "TRAIN = \"/kaggle/working/train\"\n",
    "VAL   = \"/kaggle/working/val\"\n",
    "\n",
    "# ------------------------------------\n",
    "# 1. Train/Validation Split (80/20)\n",
    "# ------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "os.makedirs(TRAIN, exist_ok=True)\n",
    "os.makedirs(VAL, exist_ok=True)\n",
    "\n",
    "for cls in os.listdir(SOURCE):\n",
    "    cls_path = os.path.join(SOURCE, cls)\n",
    "    if not os.path.isdir(cls_path): continue\n",
    "\n",
    "    files = os.listdir(cls_path)\n",
    "    train_f, val_f = train_test_split(files, test_size=0.2, random_state=SEED)\n",
    "\n",
    "    os.makedirs(os.path.join(TRAIN, cls), exist_ok=True)\n",
    "    os.makedirs(os.path.join(VAL, cls), exist_ok=True)\n",
    "\n",
    "    for f in train_f:\n",
    "        shutil.copy(os.path.join(cls_path, f), os.path.join(TRAIN, cls, f))\n",
    "    for f in val_f:\n",
    "        shutil.copy(os.path.join(cls_path, f), os.path.join(VAL, cls, f))\n",
    "\n",
    "print(\"Split done.\")\n",
    "\n",
    "# ------------------------------------\n",
    "# 2. Image Generators\n",
    "# ------------------------------------\n",
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=25,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    TRAIN,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    VAL,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "NUM_CLASSES = len(train_ds.class_indices)\n",
    "\n",
    "# ------------------------------------\n",
    "# 3. DenseNet121 Model\n",
    "# ------------------------------------\n",
    "base = DenseNet121(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(256, 256, 3)\n",
    ")\n",
    "base.trainable = False   # freeze base for stability in JEI setting\n",
    "\n",
    "model = Sequential([\n",
    "    base,\n",
    "    GlobalAveragePooling2D(),\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# ------------------------------------\n",
    "# 4. Train Model\n",
    "# ------------------------------------\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model.save(\"/kaggle/working/densenet_bio_tool.h5\")\n",
    "print(\"DenseNet model saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db6a3c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T09:33:17.472394Z",
     "iopub.status.busy": "2025-11-23T09:33:17.471708Z",
     "iopub.status.idle": "2025-11-23T10:00:31.990753Z",
     "shell.execute_reply": "2025-11-23T10:00:31.990041Z"
    },
    "papermill": {
     "duration": 1634.52845,
     "end_time": "2025-11-23T10:00:31.995676",
     "exception": false,
     "start_time": "2025-11-23T09:33:17.467226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step\n",
      "Model graph initialized!\n",
      "Found 2084 images belonging to 10 classes.\n",
      "Processed 0 images...\n",
      "Processed 200 images...\n",
      "Processed 400 images...\n",
      "Processed 600 images...\n",
      "Processed 800 images...\n",
      "Processed 1000 images...\n",
      "Processed 1200 images...\n",
      "Processed 1400 images...\n",
      "Processed 1600 images...\n",
      "Processed 1800 images...\n",
      "Processed 2000 images...\n",
      "\n",
      "Severity extraction complete!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>age</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100169.jpg</td>\n",
       "      <td>65</td>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.565765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100365.jpg</td>\n",
       "      <td>45</td>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>blast</td>\n",
       "      <td>0.095276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100382.jpg</td>\n",
       "      <td>45</td>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>brown_spot</td>\n",
       "      <td>0.434875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100513.jpg</td>\n",
       "      <td>65</td>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.565765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100632.jpg</td>\n",
       "      <td>45</td>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.484528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id  age             true_label             pred_label  severity\n",
       "0  100169.jpg   65  bacterial_leaf_blight  bacterial_leaf_blight  0.565765\n",
       "1  100365.jpg   45  bacterial_leaf_blight                  blast  0.095276\n",
       "2  100382.jpg   45  bacterial_leaf_blight             brown_spot  0.434875\n",
       "3  100513.jpg   65  bacterial_leaf_blight  bacterial_leaf_blight  0.565765\n",
       "4  100632.jpg   45  bacterial_leaf_blight  bacterial_leaf_blight  0.484528"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FINAL, FULLY-CORRECTED SEVERITY EXTRACTION PIPELINE\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------\n",
    "# 1. LOAD MODEL\n",
    "# --------------------------\n",
    "model_path = \"/kaggle/working/densenet_bio_tool.h5\"\n",
    "model = load_model(model_path)\n",
    "print(\"Model loaded!\")\n",
    "\n",
    "# Force graph build\n",
    "_ = model.predict(np.zeros((1,256,256,3)))\n",
    "print(\"Model graph initialized!\")\n",
    "\n",
    "# Split into backbone + head\n",
    "backbone = model.layers[0]       # DenseNet121\n",
    "gap_layer = model.layers[1]\n",
    "bn1       = model.layers[2]\n",
    "dense1    = model.layers[3]\n",
    "bn2       = model.layers[4]\n",
    "dense2    = model.layers[5]\n",
    "\n",
    "# --------------------------\n",
    "# 2. LOAD METADATA\n",
    "# --------------------------\n",
    "meta = pd.read_csv(\"/kaggle/input/paddy-disease-classification/train.csv\")\n",
    "\n",
    "# --------------------------\n",
    "# 3. LOAD VAL IMAGES\n",
    "# --------------------------\n",
    "IMG_SIZE = (256,256)\n",
    "VAL_DIR = \"/kaggle/working/val\"\n",
    "\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "index_to_class = {v:k for k,v in val_ds.class_indices.items()}\n",
    "\n",
    "# --------------------------\n",
    "# 4. FULLY-WORKING GRAD-CAM\n",
    "# --------------------------\n",
    "def get_gradcam(img_array, layer_name=\"conv5_block16_concat\"):\n",
    "\n",
    "    # Build model: DenseNet input -> conv layer + backbone output\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=backbone.input,\n",
    "        outputs=[\n",
    "            backbone.get_layer(layer_name).output,\n",
    "            backbone.output\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_out, backbone_feats = grad_model(img_array)\n",
    "\n",
    "        # Manually pass through classification head\n",
    "        x = gap_layer(backbone_feats)\n",
    "        x = bn1(x, training=False)\n",
    "        x = dense1(x)\n",
    "        x = bn2(x, training=False)\n",
    "        preds = dense2(x)\n",
    "\n",
    "        class_idx = tf.argmax(preds[0])\n",
    "        class_score = preds[:, class_idx]\n",
    "\n",
    "    # Compute gradients\n",
    "    grads = tape.gradient(class_score, conv_out)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n",
    "\n",
    "    conv_out = conv_out[0]\n",
    "\n",
    "    # Weighted sum of activation maps\n",
    "    heatmap = tf.reduce_sum(conv_out * pooled_grads, axis=-1)\n",
    "\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= (np.max(heatmap) + 1e-10)\n",
    "\n",
    "    return heatmap   # <- FIXED\n",
    "\n",
    "# --------------------------\n",
    "# 5. SEVERITY EXTRACTION LOOP\n",
    "# --------------------------\n",
    "records = []\n",
    "\n",
    "for i in range(len(val_ds)):\n",
    "    img = val_ds[i]  # shape (1,256,256,3)\n",
    "\n",
    "    # prediction\n",
    "    preds = model.predict(img, verbose=0)\n",
    "    pred_idx = np.argmax(preds)\n",
    "    pred_label = index_to_class[pred_idx]\n",
    "\n",
    "    # filename → metadata mapping\n",
    "    filename = val_ds.filenames[i]\n",
    "    img_id = filename.split(\"/\")[-1]\n",
    "\n",
    "    row = meta[meta[\"image_id\"] == img_id]\n",
    "    if row.empty:\n",
    "        continue\n",
    "\n",
    "    age = int(row[\"age\"].values[0])\n",
    "    true_label = row[\"label\"].values[0]\n",
    "\n",
    "    # Grad-CAM heatmap\n",
    "    heatmap = get_gradcam(img)\n",
    "\n",
    "    # Convert to mask\n",
    "    heatmap_resized = cv2.resize(heatmap, IMG_SIZE)\n",
    "    mask = (heatmap_resized > 0.4).astype(np.uint8)\n",
    "    severity = mask.sum() / mask.size\n",
    "\n",
    "    records.append([img_id, age, true_label, pred_label, severity])\n",
    "\n",
    "    if i % 200 == 0:\n",
    "        print(f\"Processed {i} images...\")\n",
    "\n",
    "# --------------------------\n",
    "# 6. SAVE CSV\n",
    "# --------------------------\n",
    "df = pd.DataFrame(records, columns=[\"image_id\", \"age\", \"true_label\", \"pred_label\", \"severity\"])\n",
    "df.to_csv(\"/kaggle/working/severity_scores.csv\", index=False)\n",
    "\n",
    "print(\"\\nSeverity extraction complete!\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "305a4525",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T10:00:32.005975Z",
     "iopub.status.busy": "2025-11-23T10:00:32.005664Z",
     "iopub.status.idle": "2025-11-23T10:00:32.970800Z",
     "shell.execute_reply": "2025-11-23T10:00:32.969741Z"
    },
    "papermill": {
     "duration": 0.971947,
     "end_time": "2025-11-23T10:00:32.972178",
     "exception": false,
     "start_time": "2025-11-23T10:00:32.000231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 2084\n",
      "     image_id  age             true_label             pred_label  severity\n",
      "0  100169.jpg   65  bacterial_leaf_blight  bacterial_leaf_blight  0.565765\n",
      "1  100365.jpg   45  bacterial_leaf_blight                  blast  0.095276\n",
      "2  100382.jpg   45  bacterial_leaf_blight             brown_spot  0.434875\n",
      "3  100513.jpg   65  bacterial_leaf_blight  bacterial_leaf_blight  0.565765\n",
      "4  100632.jpg   45  bacterial_leaf_blight  bacterial_leaf_blight  0.484528\n",
      "\n",
      "=== SUMMARY ===\n",
      "               age     severity\n",
      "count  2084.000000  2084.000000\n",
      "mean     63.750000     0.273944\n",
      "std       9.083037     0.172880\n",
      "min      45.000000     0.000000\n",
      "25%      57.000000     0.146893\n",
      "50%      67.000000     0.233810\n",
      "75%      70.000000     0.376171\n",
      "max      82.000000     0.921097\n",
      "\n",
      "Age range: 45 - 82\n",
      "Severity range: 0.0 - 0.9210968017578124\n",
      "\n",
      "Pearson r = 0.0187, p = 0.3936\n",
      "Spearman rho = 0.0422, p = 0.05383\n",
      "\n",
      "Linear regression: severity = 0.000356*age + 0.251259\n",
      "R² = 0.0003, p = 0.3936\n",
      "\n",
      "Kruskal–Wallis H = 225.7602, p = 1.285e-43\n",
      "\n",
      "Severity by age bin:\n",
      "         count      mean    median       std\n",
      "age_bin                                     \n",
      "0–20         0       NaN       NaN       NaN\n",
      "21–40        0       NaN       NaN       NaN\n",
      "41–60      850  0.265284  0.221008  0.177481\n",
      "61–80     1233  0.280011  0.240631  0.169485\n",
      "81+          1  0.155502  0.155502       NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1468399645.py:65: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  print(df.groupby('age_bin').severity.agg(['count','mean','median','std']))\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All plots saved in: /kaggle/working/jei_plots\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1468399645.py:121: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  agebin_stats = df.groupby('age_bin').severity.mean()\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# JEI ANALYSIS + PLOTS CELL\n",
    "# ================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# ---------------------------------------\n",
    "# 1. LOAD SEVERITY CSV\n",
    "# ---------------------------------------\n",
    "csv_path = \"/kaggle/working/severity_scores.csv\"\n",
    "assert os.path.exists(csv_path), \"CSV not found! Did you run severity extraction?\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "df['severity'] = pd.to_numeric(df['severity'], errors='coerce')\n",
    "df = df.dropna(subset=['age','severity'])\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "print(df.head())\n",
    "\n",
    "# ---------------------------------------\n",
    "# 2. SUMMARY STATISTICS\n",
    "# ---------------------------------------\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(df[['age','severity']].describe())\n",
    "\n",
    "print(\"\\nAge range:\", df['age'].min(), \"-\", df['age'].max())\n",
    "print(\"Severity range:\", df['severity'].min(), \"-\", df['severity'].max())\n",
    "\n",
    "# ---------------------------------------\n",
    "# 3. CORRELATIONS (JEI-SAFE)\n",
    "# ---------------------------------------\n",
    "pearson_r, pearson_p = stats.pearsonr(df['age'], df['severity'])\n",
    "spearman_r, spearman_p = stats.spearmanr(df['age'], df['severity'])\n",
    "\n",
    "print(f\"\\nPearson r = {pearson_r:.4f}, p = {pearson_p:.4g}\")\n",
    "print(f\"Spearman rho = {spearman_r:.4f}, p = {spearman_p:.4g}\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# 4. SIMPLE LINEAR REGRESSION\n",
    "# ---------------------------------------\n",
    "slope, intercept, r_val, p_val, std_err = stats.linregress(df['age'], df['severity'])\n",
    "print(f\"\\nLinear regression: severity = {slope:.6f}*age + {intercept:.6f}\")\n",
    "print(f\"R² = {r_val**2:.4f}, p = {p_val:.4g}\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# 5. KRUSKAL–WALLIS (JEI-friendly ANOVA)\n",
    "# ---------------------------------------\n",
    "groups = [grp['severity'].values for name, grp in df.groupby('true_label')]\n",
    "kw_stat, kw_p = stats.kruskal(*groups)\n",
    "print(f\"\\nKruskal–Wallis H = {kw_stat:.4f}, p = {kw_p:.4g}\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# 6. AGE BINS\n",
    "# ---------------------------------------\n",
    "bins = [0,20,40,60,80,200]\n",
    "labels = ['0–20','21–40','41–60','61–80','81+']\n",
    "df['age_bin'] = pd.cut(df['age'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "print(\"\\nSeverity by age bin:\")\n",
    "print(df.groupby('age_bin').severity.agg(['count','mean','median','std']))\n",
    "\n",
    "# ---------------------------------------\n",
    "# 7. PLOT DIRECTORY\n",
    "# ---------------------------------------\n",
    "out_dir = \"/kaggle/working/jei_plots\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------\n",
    "# 8. FIGURE 1: Age vs Severity (scatter + line)\n",
    "# ---------------------------------------\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(df['age'], df['severity'], alpha=0.35)\n",
    "x = np.linspace(df['age'].min(), df['age'].max(), 300)\n",
    "y = intercept + slope*x\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"Plant Age (days)\")\n",
    "plt.ylabel(\"Severity (fraction of leaf area)\")\n",
    "plt.title(\"Age vs Severity (scatter + trendline)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{out_dir}/figure_age_vs_severity.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ---------------------------------------\n",
    "# 9. FIGURE 2: Severity by disease (top diseases)\n",
    "# ---------------------------------------\n",
    "counts = df['true_label'].value_counts()\n",
    "diseases = counts[counts >= 20].index.tolist()  # only stable categories\n",
    "\n",
    "if len(diseases) > 0:\n",
    "    data = [df[df['true_label']==d]['severity'].values for d in diseases]\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.boxplot(data, labels=diseases, vert=True, showfliers=False)\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.ylabel(\"Severity\")\n",
    "    plt.title(\"Severity distribution across disease types\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{out_dir}/figure_severity_by_disease.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# ---------------------------------------\n",
    "# 10. FIGURE 3: Mean severity per disease\n",
    "# ---------------------------------------\n",
    "mean_sev = df.groupby('true_label').severity.mean().sort_values(ascending=False)\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.bar(mean_sev.index, mean_sev.values)\n",
    "plt.xticks(rotation=60)\n",
    "plt.ylabel(\"Mean Severity\")\n",
    "plt.title(\"Mean severity per disease type\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{out_dir}/figure_mean_severity.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ---------------------------------------\n",
    "# 11. FIGURE 4: Age-bin severity\n",
    "# ---------------------------------------\n",
    "agebin_stats = df.groupby('age_bin').severity.mean()\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(agebin_stats.index.astype(str), agebin_stats.values)\n",
    "plt.xlabel(\"Age Bin (days)\")\n",
    "plt.ylabel(\"Mean Severity\")\n",
    "plt.title(\"Severity vs Plant Age Group\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{out_dir}/figure_agebin_severity.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nAll plots saved in:\", out_dir)\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 3359805,
     "isSourceIdPinned": false,
     "sourceId": 35325,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4035.773333,
   "end_time": "2025-11-23T10:00:36.275718",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-23T08:53:20.502385",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
